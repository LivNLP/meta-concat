{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import yaml\n",
    "\n",
    "from matrix.signal_matrix_factory import SignalMatrixFactory\n",
    "from matrix.PIP_loss_calculator import MonteCarloEstimator\n",
    "from utils.tokenizer import SimpleTokenizer\n",
    "from utils.reader import ReaderFactory\n",
    "\n",
    "import numpy\n",
    "\n",
    "import sys\n",
    "PATH_TO_REPSEVAL = \"../repseval/src\"\n",
    "sys.path.insert(0, PATH_TO_REPSEVAL)\n",
    "from evaluate import evaluate_embed_matrix\n",
    "from wordreps import WordReps\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one-block example\n",
    "\n",
    "corpus_file = \"./data/text8.zip\"\n",
    "settings = [(\"glove\",\"./config/glove_sample_config.yml\"), (\"word2vec\", \"./config/word2vec_sample_config.yml\"), (\"lsa\", \"./config/lsa_sample_config.yml\")]\n",
    "algorithm, model_config = settings[2]\n",
    "\n",
    "with open(model_config, \"r\") as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "reader = ReaderFactory.produce(corpus_file[-3:])\n",
    "data = reader.read_data(corpus_file)\n",
    "tokenizer = SimpleTokenizer()\n",
    "indexed_corpus = tokenizer.do_index_data(data,\n",
    "    n_words=cfg.get('vocabulary_size'),\n",
    "    min_count=cfg.get('min_count'))\n",
    "\n",
    "factory = SignalMatrixFactory(indexed_corpus)\n",
    "\n",
    "signal_matrix = factory.produce(algorithm)\n",
    "path = signal_matrix.param_dir\n",
    "signal_matrix.inject_params(cfg)\n",
    "signal_matrix.estimate_signal()\n",
    "signal_matrix.estimate_noise()\n",
    "signal_matrix.export_estimates()\n",
    "\n",
    "pip_calculator = MonteCarloEstimator()\n",
    "pip_calculator.get_param_file(path, \"estimates.yml\")\n",
    "pip_calculator.estimate_signal()\n",
    "pip_calculator.estimate_pip_loss()\n",
    "pip_calculator.plot_pip_loss()\n",
    "\n",
    "lmdas = signal_matrix.spectrum \n",
    "myus = numpy.array(pip_calculator.estimated_signal) \n",
    "r = pip_calculator.rank\n",
    "k = 300\n",
    "\n",
    "c = numpy.dot(lmdas[:k], myus[:k]) / numpy.dot(myus[:k], myus[:k])\n",
    "print(c)\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# glove\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=503, sigma=0.21519772308477692\n",
    "optimal dimensionality is 68\n",
    "a plot of the loss is saved at params/GloVeMatrix/pip_0.5.pdf\n",
    "1.0541233958161962\n",
    "\n",
    "# w2ve\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=354, sigma=0.3998625754976759\n",
    "optimal dimensionality is 26\n",
    "a plot of the loss is saved at params/Word2VecMatrix/pip_0.5.pdf\n",
    "1.4422036180196403\n",
    "\n",
    "# lsa\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=343, sigma=0.3901904566333448\n",
    "optimal dimensionality is 24\n",
    "a plot of the loss is saved at params/LSAMatrix/pip_0.5.pdf\n",
    "1.442398466416934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the code into functions\n",
    "\n",
    "def create_signal_matrix(corpus_fname, model_config, algorithm):\n",
    "    with open(model_config, \"r\") as f:\n",
    "        cfg = yaml.load(f)\n",
    "\n",
    "    reader = ReaderFactory.produce(corpus_fname[-3:])\n",
    "    data = reader.read_data(corpus_fname)\n",
    "    tokenizer = SimpleTokenizer()\n",
    "    indexed_corpus = tokenizer.do_index_data(data,\n",
    "        n_words=cfg.get('vocabulary_size'),\n",
    "        min_count=cfg.get('min_count'))\n",
    "\n",
    "    factory = SignalMatrixFactory(indexed_corpus)\n",
    "\n",
    "    signal_matrix = factory.produce(algorithm)\n",
    "    path = signal_matrix.param_dir\n",
    "    signal_matrix.inject_params(cfg)\n",
    "    signal_matrix.estimate_signal()\n",
    "    signal_matrix.estimate_noise()\n",
    "    signal_matrix.export_estimates()\n",
    "    return cfg, path, signal_matrix, tokenizer\n",
    "\n",
    "\n",
    "def estimate_pip(path):\n",
    "    pip_calculator = MonteCarloEstimator()\n",
    "    pip_calculator.get_param_file(path, \"estimates.yml\")\n",
    "    pip_calculator.estimate_signal()\n",
    "    pip_calculator.estimate_pip_loss()\n",
    "    pip_calculator.plot_pip_loss()\n",
    "    return pip_calculator    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove ./config/glove_sample_config.yml ./data/text8.zip\n",
      "vocabulary_size=10000\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = \"./data/text8.zip\"\n",
    "settings = [(\"glove\",\"./config/glove_sample_config.yml\"), (\"word2vec\", \"./config/word2vec_sample_config.yml\"), (\"lsa\", \"./config/lsa_sample_config.yml\")]\n",
    "\n",
    "cfg = {}\n",
    "path = {}\n",
    "signal_matrix = {}\n",
    "pip_calculator = {}\n",
    "tokenizer = {}\n",
    "\n",
    "for (algorithm, model_config) in settings:\n",
    "    print(algorithm, model_config, corpus_fname)\n",
    "    cfg[algorithm], path[algorithm], signal_matrix[algorithm], tokenizer[algorithm]  = create_signal_matrix(corpus_fname, model_config, algorithm)\n",
    "    pip_calculator[algorithm] = estimate_pip(path[algorithm]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n",
      "recognise\n",
      "1221\n",
      "usually\n"
     ]
    }
   ],
   "source": [
    "# all words are indexed with the same ids across embeddings as shown below!\n",
    "print(tokenizer['glove'].dictionary['apple'])\n",
    "print(tokenizer['glove'].reversed_dictionary[9999])\n",
    "\n",
    "print(tokenizer['word2vec'].dictionary['apple'])\n",
    "print(tokenizer['word2vec'].reversed_dictionary[204])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "ws = 0.453946\n",
      "rg = 0.497549\n",
      "mc = 0.545455\n",
      "rw = 0.241380\n",
      "scws = 0.557597\n",
      "men = 0.481972\n",
      "simlex = 0.209696\n",
      "behavior = 0.168715\n",
      "mturk-771 = 0.415743\n",
      "word2vec\n",
      "ws = 0.575229\n",
      "rg = 0.700980\n",
      "mc = 0.709091\n",
      "rw = 0.331293\n",
      "scws = 0.606625\n",
      "men = 0.597068\n",
      "simlex = 0.214221\n",
      "behavior = 0.227136\n",
      "mturk-771 = 0.486107\n",
      "lsa\n",
      "ws = 0.631959\n",
      "rg = 0.803922\n",
      "mc = 0.790909\n",
      "rw = 0.428532\n",
      "scws = 0.641262\n",
      "men = 0.667809\n",
      "simlex = 0.237880\n",
      "behavior = 0.333976\n",
      "mturk-771 = 0.555348\n",
      "ws = 0.538378\n",
      "rg = 0.698529\n",
      "mc = 0.681818\n",
      "rw = 0.323674\n",
      "scws = 0.588405\n",
      "men = 0.580019\n",
      "simlex = 0.214007\n",
      "behavior = 0.288815\n",
      "mturk-771 = 0.485993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ws', 0.5383775453877891),\n",
       " ('rg', 0.698529411764706),\n",
       " ('mc', 0.6818181818181819),\n",
       " ('rw', 0.3236742060251032),\n",
       " ('scws', 0.5884053423827242),\n",
       " ('men', 0.5800185112827829),\n",
       " ('simlex', 0.21400677626267445),\n",
       " ('behavior', 0.2888147425584707),\n",
       " ('mturk-771', 0.48599293916686254)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on word embedding benchmarks (repseval)\n",
    "\n",
    "def concat(source_matrices, weights_list):\n",
    "    \"\"\"\n",
    "    Concatenates the given source embedding matrices. Can be used to perform both source-specific and\n",
    "    dimension-specific concatenation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_matrices: a list of numpy.ndarrays\n",
    "                    each representing n x k embeddng matrix. The vocabulary of the words n must be equal in all embedding matrices and their\n",
    "                    dimensionalities k can be different.\n",
    "        \n",
    "    weights_list: diagonal weights (numpy.ndarrays) for each source.\n",
    "                In the case of source-specific weighting all weights for a source will be equal, whereas for dimension-specific weighting they will be different.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    concat: a single numpy.ndarray \n",
    "            with the same n rows and the number of columns equals the sum of source dimensionalities.\n",
    "    \"\"\"\n",
    "    assert(len(source_matrices) == len(weights_list))\n",
    "    return numpy.concatenate([source_matrices[i] @ numpy.diag(weights_list[i]) for i in range(len(source_matrices))], axis=1)\n",
    "\n",
    "\n",
    "def get_source_weighted_concat_coef(lambdas, myus, k):\n",
    "    \"\"\"\n",
    "    Compute the concatenation coefficient under source-weighted concatenation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lambdas : numpy.array\n",
    "        spectrum of the signal matrix.\n",
    "        \n",
    "    myus :  numpy.array\n",
    "        spectrum of the embedding matrix.\n",
    "        \n",
    "    k : int\n",
    "        rank of the embedding matrix.\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    c : float, the concatenation coefficient.\n",
    "    \"\"\"\n",
    "    return numpy.dot(lmdas[:k], myus[:k]) / numpy.dot(myus[:k], myus[:k])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# create the embedding matrices\n",
    "k = {}\n",
    "sources = []\n",
    "for algo, _ in settings:\n",
    "    print(algo)\n",
    "    k[algo] = numpy.argmin(pip_calculator[algo].estimated_pip_loss)\n",
    "    source_mat = signal_matrix[algo].U[:,:k[algo]] @ numpy.diag(signal_matrix[algo].spectrum[:k[algo]])\n",
    "    sources.append(source_mat)\n",
    "    WR = WordReps()\n",
    "    WR.load_matrix(source_mat, tokenizer[algo].dictionary)\n",
    "    evaluate_embed_matrix(WR, mode=\"lex\")\n",
    "    \n",
    "weights_list = [numpy.ones(k[algo]) for algo, _ in settings]\n",
    "M = concat(sources, weights_list)\n",
    "WR = WordReps()\n",
    "WR.load_matrix(M, tokenizer[algo].dictionary)\n",
    "evaluate_embed_matrix(WR, mode=\"lex\")\n",
    "\n",
    "# source-weighted concatenation\n",
    "weights_list = []\n",
    "for algo, _ in settings:\n",
    "    c = get_source_weighted_concat_coef(signal_matrix[algo].spectrum, \n",
    "                                        numpy.array(pip_calculator[algo].estimated_signal), \n",
    "                                       k[algo])\n",
    "    weights_list.append(c * numpy.ones(k[algo]))\n",
    "M = concat(sources, weights_list)\n",
    "WR = WordReps()\n",
    "WR.load_matrix(M, tokenizer[algo].dictionary)\n",
    "evaluate_embed_matrix(WR, mode=\"lex\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
