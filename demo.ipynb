{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import yaml\n",
    "\n",
    "from matrix.signal_matrix_factory import SignalMatrixFactory\n",
    "from matrix.PIP_loss_calculator import MonteCarloEstimator\n",
    "from utils.tokenizer import SimpleTokenizer\n",
    "from utils.reader import ReaderFactory\n",
    "\n",
    "import numpy\n",
    "\n",
    "import sys\n",
    "PATH_TO_REPSEVAL = \"../repseval/src\"\n",
    "sys.path.insert(0, PATH_TO_REPSEVAL)\n",
    "from evaluate import evaluate_embed_matrix\n",
    "from wordreps import WordReps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size=1909\n",
      "n=1909, rank=343, sigma=0.3901904566333448\n",
      "optimal dimensionality is 24\n",
      "a plot of the loss is saved at params/LSAMatrix/pip_0.5.pdf\n",
      "1.442398466416934\n"
     ]
    }
   ],
   "source": [
    "# one-block example\n",
    "\n",
    "corpus_file = \"./data/text8.zip\"\n",
    "settings = [(\"glove\",\"./config/glove_sample_config.yml\"), (\"word2vec\", \"./config/word2vec_sample_config.yml\"), (\"lsa\", \"./config/lsa_sample_config.yml\")]\n",
    "algorithm, model_config = settings[2]\n",
    "\n",
    "with open(model_config, \"r\") as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "reader = ReaderFactory.produce(corpus_file[-3:])\n",
    "data = reader.read_data(corpus_file)\n",
    "tokenizer = SimpleTokenizer()\n",
    "indexed_corpus = tokenizer.do_index_data(data,\n",
    "    n_words=cfg.get('vocabulary_size'),\n",
    "    min_count=cfg.get('min_count'))\n",
    "\n",
    "factory = SignalMatrixFactory(indexed_corpus)\n",
    "\n",
    "signal_matrix = factory.produce(algorithm)\n",
    "path = signal_matrix.param_dir\n",
    "signal_matrix.inject_params(cfg)\n",
    "signal_matrix.estimate_signal()\n",
    "signal_matrix.estimate_noise()\n",
    "signal_matrix.export_estimates()\n",
    "\n",
    "pip_calculator = MonteCarloEstimator()\n",
    "pip_calculator.get_param_file(path, \"estimates.yml\")\n",
    "pip_calculator.estimate_signal()\n",
    "pip_calculator.estimate_pip_loss()\n",
    "pip_calculator.plot_pip_loss()\n",
    "\n",
    "lmdas = signal_matrix.spectrum \n",
    "myus = numpy.array(pip_calculator.estimated_signal) \n",
    "r = pip_calculator.rank\n",
    "k = 300\n",
    "\n",
    "c = numpy.dot(lmdas[:k], myus[:k]) / numpy.dot(myus[:k], myus[:k])\n",
    "print(c)\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# glove\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=503, sigma=0.21519772308477692\n",
    "optimal dimensionality is 68\n",
    "a plot of the loss is saved at params/GloVeMatrix/pip_0.5.pdf\n",
    "1.0541233958161962\n",
    "\n",
    "# w2ve\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=354, sigma=0.3998625754976759\n",
    "optimal dimensionality is 26\n",
    "a plot of the loss is saved at params/Word2VecMatrix/pip_0.5.pdf\n",
    "1.4422036180196403\n",
    "\n",
    "# lsa\n",
    "vocabulary_size=1909\n",
    "n=1909, rank=343, sigma=0.3901904566333448\n",
    "optimal dimensionality is 24\n",
    "a plot of the loss is saved at params/LSAMatrix/pip_0.5.pdf\n",
    "1.442398466416934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the code into functions\n",
    "\n",
    "def create_signal_matrix(corpus_fname, model_config, algorithm):\n",
    "    with open(model_config, \"r\") as f:\n",
    "        cfg = yaml.load(f)\n",
    "\n",
    "    reader = ReaderFactory.produce(corpus_fname[-3:])\n",
    "    data = reader.read_data(corpus_fname)\n",
    "    tokenizer = SimpleTokenizer()\n",
    "    indexed_corpus = tokenizer.do_index_data(data,\n",
    "        n_words=cfg.get('vocabulary_size'),\n",
    "        min_count=cfg.get('min_count'))\n",
    "\n",
    "    factory = SignalMatrixFactory(indexed_corpus)\n",
    "\n",
    "    signal_matrix = factory.produce(algorithm)\n",
    "    path = signal_matrix.param_dir\n",
    "    signal_matrix.inject_params(cfg)\n",
    "    signal_matrix.estimate_signal()\n",
    "    signal_matrix.estimate_noise()\n",
    "    signal_matrix.export_estimates()\n",
    "    return cfg, path, signal_matrix, tokenizer\n",
    "\n",
    "\n",
    "def estimate_pip(path):\n",
    "    pip_calculator = MonteCarloEstimator()\n",
    "    pip_calculator.get_param_file(path, \"estimates.yml\")\n",
    "    pip_calculator.estimate_signal()\n",
    "    pip_calculator.estimate_pip_loss()\n",
    "    pip_calculator.plot_pip_loss()\n",
    "    return pip_calculator    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove ./config/glove_sample_config.yml ./data/text8.zip\n",
      "vocabulary_size=10000\n",
      "n=10000, rank=2623, sigma=0.1472030442613216\n",
      "optimal dimensionality is 738\n",
      "a plot of the loss is saved at params/GloVeMatrix/pip_0.5.pdf\n",
      "word2vec ./config/word2vec_sample_config.yml ./data/text8.zip\n",
      "vocabulary_size=10000\n",
      "n=10000, rank=2280, sigma=0.35662454111971503\n",
      "optimal dimensionality is 119\n",
      "a plot of the loss is saved at params/Word2VecMatrix/pip_0.5.pdf\n",
      "lsa ./config/lsa_sample_config.yml ./data/text8.zip\n",
      "vocabulary_size=10000\n",
      "n=10000, rank=2232, sigma=0.3521004885954202\n",
      "optimal dimensionality is 119\n",
      "a plot of the loss is saved at params/LSAMatrix/pip_0.5.pdf\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = \"./data/text8.zip\"\n",
    "settings = [(\"glove\",\"./config/glove_sample_config.yml\"), (\"word2vec\", \"./config/word2vec_sample_config.yml\"), (\"lsa\", \"./config/lsa_sample_config.yml\")]\n",
    "\n",
    "cfg = {}\n",
    "path = {}\n",
    "signal_matrix = {}\n",
    "pip_calculator = {}\n",
    "tokenizer = {}\n",
    "\n",
    "for (algorithm, model_config) in settings:\n",
    "    print(algorithm, model_config, corpus_fname)\n",
    "    cfg[algorithm], path[algorithm], signal_matrix[algorithm], tokenizer[algorithm]  = create_signal_matrix(corpus_fname, model_config, algorithm)\n",
    "    pip_calculator[algorithm] = estimate_pip(path[algorithm]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n",
      "recognise\n",
      "1221\n",
      "usually\n"
     ]
    }
   ],
   "source": [
    "# all words are indexed with the same ids across embeddings as shown below!\n",
    "print(tokenizer['glove'].dictionary['apple'])\n",
    "print(tokenizer['glove'].reversed_dictionary[9999])\n",
    "\n",
    "print(tokenizer['word2vec'].dictionary['apple'])\n",
    "print(tokenizer['word2vec'].reversed_dictionary[204])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on word embedding benchmarks (repseval)\n",
    "\n",
    "# create the embedding matrices\n",
    "k = {}\n",
    "source = {}\n",
    "for algo, _ in settings:\n",
    "    print(algo)\n",
    "    k[algo] = numpy.argmin(pip_calculator[algo].estimated_pip_loss)\n",
    "    source[algo] = signal_matrix[algo].U[:,:k[algo]] @ numpy.diag(signal_matrix[algo].spectrum[:k[algo]])\n",
    "    print(source[algo].shape)\n",
    "    \n",
    "    WR = WordReps()\n",
    "    WR.load_matrix(source[algo], tokenizer[algo].dictionary)\n",
    "    evaluate_embed_matrix(WR, mode=\"lex\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
